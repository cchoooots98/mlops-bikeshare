name: CD_Staging

on:
  push:
    branches: [main]
  workflow_dispatch:

env:
  AWS_REGION: ${{ vars.AWS_REGION }}                  # e.g., ca-central-1
  ENDPOINT_NAME: ${{ vars.ENDPOINT_STAGING }}         # e.g., bikeshare-staging
  INSTANCE_TYPE: ${{ vars.INSTANCE_STAGING }}         # e.g., ml.m5.large
  ECR_IMAGE_URI: ${{ vars.ECR_IMAGE_URI }}            # e.g., .../mlflow-pyfunc:3.3.2-v5
  DEFAULT_S3_MODEL_TAR: ${{ vars.S3_MODEL_TAR }}      # default model tar to deploy
  # ---- Secrets ----
  SM_EXECUTION_ROLE_Arn: ${{ secrets.SM_EXECUTION_ROLE_Arn }}

permissions:
  id-token: write
  contents: read

concurrency:
  group: staging-deploy
  cancel-in-progress: false  # Avoid interrupting a live rollout

jobs:
  deploy-staging:
    name: Deploy to SageMaker (staging)
    runs-on: ubuntu-latest
    environment: staging

    steps:
      - name: Checkout
        uses: actions/checkout@v4
      
      - name: Configure AWS (OIDC)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-region: ${{ env.AWS_REGION }}
          role-to-assume: ${{ secrets.AWS_ROLE_TO_ASSUME }}
          role-session-name: gh-actions-staging

      - name: WhoAmI (debug)
        # English: Quick sanity check that credentials work
        run: aws sts get-caller-identity

      # OPTIONAL: If you routinely rebuild/push the BYOC image, add ECR login + docker build/push here.

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install deploy deps
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt || true
          python - <<'PY'
          import importlib.util, subprocess, sys
          for pkg in ("boto3","botocore"):
              if importlib.util.find_spec(pkg) is None:
                  subprocess.check_call([sys.executable, "-m", "pip", "install", pkg])
          PY

      - name: Capture previous endpoint config (for rollback)
        id: prev
        shell: bash
        run: |
          set -euo pipefail
          PREV_CFG=$(aws sagemaker describe-endpoint \
            --endpoint-name "${ENDPOINT_NAME}" \
            --query 'EndpointConfigName' --output text 2>/dev/null || echo "NONE")
          echo "prev_config=$PREV_CFG" >> "$GITHUB_OUTPUT"
          echo "PreviousConfig=$PREV_CFG"

      - name: Deploy (blue/green create-or-update)
        # English: Same parameters as your local PowerShell command
        run: |
          set -euo pipefail
          python pipelines/deploy_via_sagemaker_sdk.py \
            --endpoint-name "${ENDPOINT_NAME}" \
            --role-arn "${SM_EXECUTION_ROLE_Arn}" \
            --image-uri "${ECR_IMAGE_URI}" \
            --model-data "${DEFAULT_S3_MODEL_TAR}" \
            --instance-type "${INSTANCE_TYPE}" \
            --region "${AWS_REGION}"

      - name: Smoke test (use repo script to match schema exactly)
        # English: Reuse your test/smoke_invoke.py to avoid column/order mismatch
        run: |
          set -euo pipefail
          python test/smoke_invoke.py --endpoint-name "${ENDPOINT_NAME}" --region "${AWS_REGION}"
      
      - name: Configure AWS (OIDC) for rollback
        if: failure()
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-region: ${{ env.AWS_REGION }}
          role-to-assume: ${{ secrets.AWS_ROLE_TO_ASSUME }}
          role-session-name: gh-actions-staging-rollback



      - name: Rollback on failure
        if: failure() && steps.prev.outputs.prev_config != 'NONE'
        run: |
          echo "Smoke test failed â€” rolling back."
          aws sagemaker update-endpoint \
            --endpoint-name "${ENDPOINT_NAME}" \
            --endpoint-config-name "${{ steps.prev.outputs.prev_config }}" \
            --region "${AWS_REGION}"
